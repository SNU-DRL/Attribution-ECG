{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Localization metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "MITDB_RESULT = \"results_evaluation_localization/mitdb_resnet18_7_bs32_lr5e-2_wd1e-4_ep20/_final_results.csv\"\n",
    "mitdb_df = pd.read_csv(MITDB_RESULT, index_col=0).round(3)\n",
    "SVDB_RESULT = \"results_evaluation_localization/svdb_resnet18_7_bs32_lr1e-2_wd1e-4_ep20/_final_results.csv\"\n",
    "svdb_df = pd.read_csv(SVDB_RESULT, index_col=0).round(3)\n",
    "INCARTDB_RESULT = \"results_evaluation_localization/incartdb_resnet18_7_bs32_lr1e-3_wd1e-4_ep20/_final_results.csv\"\n",
    "incartdb_df = pd.read_csv(INCARTDB_RESULT, index_col=0).round(3)\n",
    "ICENTIA_RESULT = \"results_evaluation_localization/icentia11k_resnet18_7_bs32_lr1e-3_wd1e-4_ep20/_final_results.csv\"\n",
    "icentia_df = pd.read_csv(ICENTIA_RESULT, index_col=0).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_DIR = \"./tables_localization\"\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_order = [\"guided_gradcam\", \"guided_backprop\", \"gradcam\", \"deep_shap\", \"integrated_gradients\", \"deep_lift\", \"lime\", \"input_gradient\", \"kernel_shap\", \"saliency\", \"lrp\", \"random_baseline\"]\n",
    "methods_index = []\n",
    "for method in methods_order:\n",
    "    methods_index.append(f\"{method}_results\")\n",
    "    methods_index.append(f\"{method}_results_absolute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "mitdb_df = mitdb_df.reindex(methods_index)\n",
    "svdb_df = svdb_df.reindex(methods_index)\n",
    "incartdb_df = incartdb_df.reindex(methods_index)\n",
    "icentia_df = icentia_df.reindex(methods_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"attribution_localization\", \"auc\", \"pointing_game\", \"relevance_rank_accuracy\"]\n",
    "metrics_strs = [f\"{metric}_str\" for metric in metrics]\n",
    "metrics_ranks = [f\"{metric}_rank\" for metric in metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [mitdb_df, svdb_df, incartdb_df, icentia_df]\n",
    "for df in dfs:\n",
    "    for metric in metrics:\n",
    "        df[f\"{metric}_rank\"] = df[f\"{metric}_mean\"].rank(ascending=False, method=\"min\").astype(int)\n",
    "        df[f\"{metric}_str\"] = df.apply(lambda row: f\"{row[f'{metric}_mean']:.3f}Â±{row[f'{metric}_stddev']:.3f} ({int(row[f'{metric}_rank'])})\", axis=1)\n",
    "    df[\"overall_rank\"] = df[metrics_ranks].mean(axis=1).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "mitdb_df[metrics_strs + [\"overall_rank\"]].to_csv(os.path.join(RESULT_DIR, \"full_mitdb.csv\"))\n",
    "svdb_df[metrics_strs + [\"overall_rank\"]].to_csv(os.path.join(RESULT_DIR, \"full_svdb.csv\"))\n",
    "incartdb_df[metrics_strs + [\"overall_rank\"]].to_csv(os.path.join(RESULT_DIR, \"full_incartdb.csv\"))\n",
    "icentia_df[metrics_strs + [\"overall_rank\"]].to_csv(os.path.join(RESULT_DIR, \"full_icentia.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ranks = pd.concat([mitdb_df[metrics_ranks], svdb_df[metrics_ranks], incartdb_df[metrics_ranks], icentia_df[metrics_ranks]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ranks.mean(axis=1).round(1).to_csv(os.path.join(RESULT_DIR, \"full_ranks.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_methods = [\"guided_gradcam_results_absolute\", \"guided_backprop_results_absolute\",  \"gradcam_results\", \"deep_shap_results_absolute\", \"integrated_gradients_results_absolute\", \"deep_lift_results_absolute\", \"lime_results\", \"input_gradient_results_absolute\", \"kernel_shap_results\", \"saliency_results_absolute\", \"lrp_results_absolute\", \"random_baseline_results\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_mitdb_df = mitdb_df.loc[selected_methods]\n",
    "selected_svdb_df = svdb_df.loc[selected_methods]\n",
    "selected_incartdb_df = incartdb_df.loc[selected_methods]\n",
    "selected_icentia_df = icentia_df.loc[selected_methods]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_dfs = [selected_mitdb_df, selected_svdb_df, selected_incartdb_df, selected_icentia_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in selected_dfs:\n",
    "    for metric in metrics:\n",
    "        df[f\"{metric}_rank\"] = df[f\"{metric}_mean\"].rank(ascending=False, method=\"min\").astype(int)\n",
    "        df[f\"{metric}_str\"] = df.apply(lambda row: f\"{row[f'{metric}_mean']:.3f} ({int(row[f'{metric}_rank'])})\", axis=1)\n",
    "\n",
    "    df[\"overall_rank\"] = df[metrics_ranks].mean(axis=1).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_mitdb_df[metrics_strs + [\"overall_rank\"]].to_csv(os.path.join(RESULT_DIR, \"selected_mitdb.csv\"))\n",
    "selected_svdb_df[metrics_strs + [\"overall_rank\"]].to_csv(os.path.join(RESULT_DIR, \"selected_svdb.csv\"))\n",
    "selected_incartdb_df[metrics_strs + [\"overall_rank\"]].to_csv(os.path.join(RESULT_DIR, \"selected_incartdb.csv\"))\n",
    "selected_icentia_df[metrics_strs + [\"overall_rank\"]].to_csv(os.path.join(RESULT_DIR, \"selected_icentia.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_all_ranks = pd.concat([selected_mitdb_df[metrics_ranks], selected_svdb_df[metrics_ranks], selected_incartdb_df[metrics_ranks], selected_icentia_df[metrics_ranks]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_all_ranks.mean(axis=1).round(1).to_csv(os.path.join(RESULT_DIR, \"selected_ranks.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faithfulness metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "MITDB_RESULT = \"results_evaluation_faithfulness/mitdb_resnet18_7_bs32_lr5e-2_wd1e-4_ep20/_final_results.csv\"\n",
    "mitdb_df = pd.read_csv(MITDB_RESULT, index_col=0).round(3)\n",
    "SVDB_RESULT = \"results_evaluation_faithfulness/svdb_resnet18_7_bs32_lr1e-2_wd1e-4_ep20/_final_results.csv\"\n",
    "svdb_df = pd.read_csv(SVDB_RESULT, index_col=0).round(3)\n",
    "INCARTDB_RESULT = \"results_evaluation_faithfulness/incartdb_resnet18_7_bs32_lr1e-3_wd1e-4_ep20/_final_results.csv\"\n",
    "incartdb_df = pd.read_csv(INCARTDB_RESULT, index_col=0).round(3)\n",
    "ICENTIA_RESULT = \"results_evaluation_faithfulness/icentia11k_resnet18_7_bs32_lr1e-3_wd1e-4_ep20/_final_results.csv\"\n",
    "icentia_df = pd.read_csv(ICENTIA_RESULT, index_col=0).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_DIR = \"./tables_faithfulness\"\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_order = [\"lime\", \"deep_shap\", \"integrated_gradients\", \"deep_lift\", \"guided_backprop\", \"input_gradient\", \"guided_gradcam\", \"kernel_shap\", \"gradcam\", \"lrp\", \"saliency\", \"random_baseline\"]\n",
    "methods_index = []\n",
    "for method in methods_order:\n",
    "    methods_index.append(f\"{method}_results\")\n",
    "    methods_index.append(f\"{method}_results_absolute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "mitdb_df = mitdb_df.reindex(methods_index)\n",
    "svdb_df = svdb_df.reindex(methods_index)\n",
    "incartdb_df = incartdb_df.reindex(methods_index)\n",
    "icentia_df = icentia_df.reindex(methods_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {\n",
    "    \"mitdb\": mitdb_df,\n",
    "    \"svdb\": svdb_df,\n",
    "    \"incartdb\": incartdb_df,\n",
    "    \"icentia\": icentia_df\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"region_perturbation_morf\", \"region_perturbation_lerf\", \"faithfulness_correlation\"]\n",
    "metrics_strs = [f\"{metric}_str\" for metric in metrics]\n",
    "metrics_ranks = [f\"{metric}_rank\" for metric in metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in dfs.items():\n",
    "        metric = \"region_perturbation_morf\"\n",
    "        df[f\"{metric}_rank\"] = df[f\"{metric}_mean\"].rank(ascending=False, method=\"min\").astype(int)\n",
    "        df[f\"{metric}_str\"] = df.apply(lambda row: f\"{row[f'{metric}_mean']:.3f}Â±{row[f'{metric}_stddev']:.3f} ({int(row[f'{metric}_rank'])})\", axis=1)\n",
    "        \n",
    "        metric = \"region_perturbation_lerf\"\n",
    "        df[f\"{metric}_rank\"] = df[f\"{metric}_mean\"].rank(ascending=True, method=\"min\").astype(int)\n",
    "        df[f\"{metric}_str\"] = df.apply(lambda row: f\"{row[f'{metric}_mean']:.3f}Â±{row[f'{metric}_stddev']:.3f} ({int(row[f'{metric}_rank'])})\", axis=1)\n",
    "        \n",
    "        metric = \"faithfulness_correlation\"\n",
    "        df[f\"{metric}_rank\"] = df[f\"{metric}_mean\"].rank(ascending=False, method=\"min\").astype(int)\n",
    "        df[f\"{metric}_str\"] = df.apply(lambda row: f\"{row[f'{metric}_mean']:.3f}Â±{row[f'{metric}_stddev']:.3f} ({int(row[f'{metric}_rank'])})\", axis=1)\n",
    "        \n",
    "        df[\"overall_rank\"] = df[metrics_ranks].mean(axis=1).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "mitdb_df[metrics_strs + [\"overall_rank\"]].to_csv(os.path.join(RESULT_DIR, \"full_mitdb.csv\"))\n",
    "svdb_df[metrics_strs + [\"overall_rank\"]].to_csv(os.path.join(RESULT_DIR, \"full_svdb.csv\"))\n",
    "incartdb_df[metrics_strs + [\"overall_rank\"]].to_csv(os.path.join(RESULT_DIR, \"full_incartdb.csv\"))\n",
    "icentia_df[metrics_strs + [\"overall_rank\"]].to_csv(os.path.join(RESULT_DIR, \"full_icentia.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ranks = pd.concat([mitdb_df[metrics_ranks], svdb_df[metrics_ranks], incartdb_df[metrics_ranks], icentia_df[metrics_ranks]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ranks.mean(axis=1).round(1).to_csv(os.path.join(RESULT_DIR, \"full_ranks.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_methods = [\"lime_results\", \"deep_shap_results\", \"integrated_gradients_results_absolute\", \"deep_lift_results\", \"guided_backprop_results_absolute\", \"input_gradient_results_absolute\", \"guided_gradcam_results_absolute\", \"kernel_shap_results\", \"gradcam_results\", \"lrp_results_absolute\", \"saliency_results_absolute\", \"random_baseline_results\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_mitdb_df = mitdb_df.loc[selected_methods]\n",
    "selected_svdb_df = svdb_df.loc[selected_methods]\n",
    "selected_incartdb_df = incartdb_df.loc[selected_methods]\n",
    "selected_icentia_df = icentia_df.loc[selected_methods]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_dfs = {\n",
    "    \"mitdb\": selected_mitdb_df,\n",
    "    \"svdb\": selected_svdb_df,\n",
    "    \"incartdb\": selected_incartdb_df,\n",
    "    \"icentia\": selected_icentia_df\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in selected_dfs.items():\n",
    "        metric = \"region_perturbation_morf\"\n",
    "        df[f\"{metric}_rank\"] = df[f\"{metric}_mean\"].rank(ascending=False, method=\"min\").astype(int)\n",
    "        df[f\"{metric}_str\"] = df.apply(lambda row: f\"{row[f'{metric}_mean']:.3f} ({int(row[f'{metric}_rank'])})\", axis=1)\n",
    "        \n",
    "        metric = \"region_perturbation_lerf\"\n",
    "        df[f\"{metric}_rank\"] = df[f\"{metric}_mean\"].rank(ascending=True, method=\"min\").astype(int)\n",
    "        df[f\"{metric}_str\"] = df.apply(lambda row: f\"{row[f'{metric}_mean']:.3f} ({int(row[f'{metric}_rank'])})\", axis=1)\n",
    "        \n",
    "        metric = \"faithfulness_correlation\"\n",
    "        df[f\"{metric}_rank\"] = df[f\"{metric}_mean\"].rank(ascending=False, method=\"min\").astype(int)\n",
    "        df[f\"{metric}_str\"] = df.apply(lambda row: f\"{row[f'{metric}_mean']:.3f} ({int(row[f'{metric}_rank'])})\", axis=1)\n",
    "        \n",
    "        df[\"overall_rank\"] = df[metrics_ranks].mean(axis=1).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_mitdb_df[metrics_strs + [\"overall_rank\"]].to_csv(os.path.join(RESULT_DIR, \"selected_mitdb.csv\"))\n",
    "selected_svdb_df[metrics_strs + [\"overall_rank\"]].to_csv(os.path.join(RESULT_DIR, \"selected_svdb.csv\"))\n",
    "selected_incartdb_df[metrics_strs + [\"overall_rank\"]].to_csv(os.path.join(RESULT_DIR, \"selected_incartdb.csv\"))\n",
    "selected_icentia_df[metrics_strs + [\"overall_rank\"]].to_csv(os.path.join(RESULT_DIR, \"selected_icentia.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_all_ranks = pd.concat([selected_mitdb_df[metrics_ranks], selected_svdb_df[metrics_ranks], selected_incartdb_df[metrics_ranks], selected_icentia_df[metrics_ranks]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_all_ranks.mean(axis=1).round(1).to_csv(os.path.join(RESULT_DIR, \"selected_ranks.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "attribution-ecg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
